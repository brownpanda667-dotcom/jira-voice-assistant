{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load and print the .env file and print the OPENAI_API_KEY variable",
   "id": "934e7cf75ab0a17"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:22:30.385653Z",
     "start_time": "2025-12-08T16:22:30.376340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"OPENAI_API_KEY Length:\", len(openai_api_key))"
   ],
   "id": "4f076ce0d39f0c46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY Length: 164\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hello world with LangChain and OpenAI's GPT-3.5 Turbo",
   "id": "a662908fce303aa3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:22:32.324380Z",
     "start_time": "2025-12-08T16:22:30.395035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "response=llm.invoke(\"Hello, world! This is my first call to LangChain using OpenAI's GPT-3.5 Turbo model.\")\n",
    "\n",
    "print(response.content)\n"
   ],
   "id": "af9801424d2c9e7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome to LangChain, powered by OpenAI's powerful GPT-3.5 Turbo model. How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prompt Templates",
   "id": "909b2a400baabae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:22:33.942941Z",
     "start_time": "2025-12-08T16:22:32.330365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=\"Tell me a joke about {topic}?\",\n",
    ")\n",
    "\n",
    "prompt = template.format(topic=\"chickens\")\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ],
   "id": "bd9bd0ae2c6282d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the chicken join a band? Because it had the drumsticks!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Chaining Steps",
   "id": "aa24b9b3d1fe84f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:22:35.176189Z",
     "start_time": "2025-12-08T16:22:33.952912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain = template | llm\n",
    "response = chain.invoke({\"topic\": \"computers\"})\n",
    "print(response.content)"
   ],
   "id": "ff55176cddfb5ffa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the computer cold?\n",
      "\n",
      "It left its Windows open!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Output Parser",
   "id": "8104fbbad1c3c90e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:22:35.792550Z",
     "start_time": "2025-12-08T16:22:35.192200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"topic\": \"programming\"})\n",
    "print(response)"
   ],
   "id": "34f4c1c5228b2d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do programmers prefer dark mode? Because light attracts bugs!\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Defining and using tools",
   "id": "9e706b9bf8888b15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:22:37.736937Z",
     "start_time": "2025-12-08T16:22:35.802912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"multiply two numbers together.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# create a list of tools\n",
    "tools = [multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "response = llm_with_tools.invoke(\"What is 6 multiplied by 7?\")\n",
    "\n",
    "print(response)\n",
    "\n"
   ],
   "id": "7b4bdccef074fade",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 55, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CkYIOdvUUuiG2yCc5IRK6AeDl8Q5E', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='lc_run--019afec5-a020-7551-b39d-3873182b1ae0-0' tool_calls=[{'name': 'multiply', 'args': {'a': 6, 'b': 7}, 'id': 'call_uo4T8bSPJvihN7rOwAGuNsi1', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 7, 'b': 6}, 'id': 'call_Hpshtxb6rtt6ZeufDf6qinsP', 'type': 'tool_call'}] usage_metadata={'input_tokens': 55, 'output_tokens': 49, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:22:37.745558Z",
     "start_time": "2025-12-08T16:22:37.742864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tool_call = response.tool_calls[0]\n",
    "arguments = tool_call[\"args\"]\n",
    "result = multiply.invoke(arguments)\n",
    "print(\"Tool Result:\", result)"
   ],
   "id": "4e867ac95a7b78ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Result: 42\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agent Executor (or in newer versions, a Graph)",
   "id": "601dfebaa04d9538"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:22:37.781144Z",
     "start_time": "2025-12-08T16:22:37.774228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# We already have 'llm' and 'tools' from before\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant who is good at math.\"\n",
    ")"
   ],
   "id": "65a76f47962f2bc9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T16:24:04.573471Z",
     "start_time": "2025-12-08T16:24:02.331387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# We pass a dictionary with a \"messages\" key\n",
    "# The value is a list containing our user message\n",
    "response = agent.invoke({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What is 6 multiplied by 7?\"}]\n",
    "})\n",
    "\n",
    "# Print the last message in the response (which is the AI's final answer)\n",
    "print(response[\"messages\"][-1].content)"
   ],
   "id": "e2b35390ea8b0537",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 multiplied by 7 is 42.\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
